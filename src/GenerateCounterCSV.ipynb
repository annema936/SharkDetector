{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import http.client\n",
    "from urllib.parse import urlencode\n",
    "import logging\n",
    "from datetime import datetime,timedelta,date\n",
    "import pandas as pd\n",
    "import ta\n",
    "import os\n",
    "from klse_scrapper import *\n",
    "from session_handler import *\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import urllib.parse\n",
    "import zipfile\n",
    "from workalendar.asia import Malaysia\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ggplot import *\n",
    "# Standard plotly imports\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "# Using plotly + cufflinks in offline mode\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "init_notebook_mode(connected=True)\n",
    "from loess.loess_1d import loess_1d\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.plot import plot_plotly\n",
    "import plotly.offline as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_handler(event):\n",
    "#Demonstrates a simple HTTP request from Lambda\n",
    "    logger.debug(event)\n",
    "    symbol=event['counter']\n",
    "    resolution=event['resolution']\n",
    "    #end_time=int(datetime.now().timestamp())\n",
    "    #start_time=int((datetime.now() - timedelta(hours=24)).timestamp())\n",
    "    start_time=event['from']\n",
    "    end_time=event['to']\n",
    "    logger.debug(\"Start time:\" + str(start_time) + \" End time:\" + str(end_time))\n",
    "    headers = {\"Content-type\": \"application/json\"}\n",
    "    payload = {\"symbol\":symbol,\"resolution\":resolution,\"from\":start_time,\"to\":end_time}\n",
    "    logger.debug(urlencode(payload))\n",
    "    conn = http.client.HTTPSConnection(\"www.klsescreener.com\")\n",
    "    conn.request(\"GET\", \"/v2/trading_view/history?\"+urlencode(payload))\n",
    "    response = conn.getresponse()\n",
    "    res = response.read().decode() #load data into a dict of objects, posts\n",
    "    if(json.loads(res)['s']=='ok'):\n",
    "        return pd.read_json(res)\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_handler_yf(event):\n",
    "#Demonstrates a simple HTTP request from Lambda\n",
    "    logger.debug(event)\n",
    "    symbol=event['counter']\n",
    "    resolution=event['resolution']\n",
    "    #end_time=int(datetime.now().timestamp())\n",
    "    #start_time=int((datetime.now() - timedelta(hours=24)).timestamp())\n",
    "    start_time=datetime.fromtimestamp(event['from']).strftime(\"%Y-%m-%d\")\n",
    "    end_time=datetime.fromtimestamp(event['to']).strftime(\"%Y-%m-%d\")\n",
    "    ticker = yf.Ticker(str(event['counter'])+'.KL')\n",
    "    hist = ticker.history(start=start_time, end=end_time,interval=event['resolution'])\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_requests(event):\n",
    "    #split query time if longer than 1 day\n",
    "    events=[]\n",
    "    if(event['resolution']=='1m'):\n",
    "        diff=event['to']-event['from']\n",
    "        if(diff>86400):\n",
    "            while(event['to']>event['from']):                \n",
    "                event_copy=event.copy()\n",
    "                event_copy['from']=event_copy['to']-86400\n",
    "                event['to']=event['to']-86400\n",
    "                events.append(event_copy)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(df):\n",
    "    df['t']=pd.to_datetime(df['t'],unit='s')\n",
    "    df=df.set_index('t').drop(['s'],axis=1)\n",
    "    df.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noindex(df):\n",
    "    df['t']=pd.to_datetime(df['t'],unit='s')\n",
    "    df=df.drop(['s','t'],axis=1)\n",
    "    df.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_event_lists(lists_,from_,to_,resolution_='1m',csv_=1):\n",
    "    events=[]\n",
    "    for list_ in lists_:\n",
    "        event={\"category\":list_['cat'],\"symbol\":list_['symbol'],\"counter\":list_['code'],\"resolution\":resolution_, \"from\":from_,\"to\":to_, \"write_csv\":csv_}\n",
    "        events.append(event)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(session, url, save_path, chunk_size=128):\n",
    "    r = session.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_data(events):\n",
    "    for event_ in events:\n",
    "        events__ = distribute_requests(event_)\n",
    "        for event__ in events__:\n",
    "            df_=lambda_handler_yf(event__)\n",
    "            name_=event__['symbol']+'_'+str(event__['counter'])\n",
    "            dir_=os.path.join('history','price')\n",
    "            dir_=os.path.join(dir_,event_['category'])\n",
    "            dir_=os.path.join(dir_,name_)\n",
    "            if len(df_)>0:        \n",
    "                if not os.path.exists(dir_): os.makedirs(dir_)\n",
    "                if(event__['write_csv']):\n",
    "                    csv_name=name_+'_'+datetime.fromtimestamp(event__['from']).strftime(\"%Y-%m-%d\")\n",
    "                    df_.to_csv(os.path.join(dir_,csv_name+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_quote_movements(event):\n",
    "    date_=datetime.fromtimestamp(event['to'])\n",
    "    cal = Malaysia()\n",
    "    if(cal.is_working_day(date(date_.year,date_.month,date_.day))):\n",
    "        date_=date_.strftime(\"%Y%m%d\")\n",
    "        quotes_url='http://www.shareinvestor.com/prices/price_download_zip_file.zip'\n",
    "        params = {'type': 'quotemovements', 'counter': event['counter']+'.MY', 'date':date_}\n",
    "        params=urllib.parse.urlencode(params)\n",
    "        quotes_url=quotes_url+'?'+params\n",
    "        session=read_session()\n",
    "        dir_='history/quote_movements/'\n",
    "        dir_=os.path.join(dir_,event['category'])\n",
    "        name=event['symbol']+'_'+event['counter']\n",
    "        dir_=os.path.join(dir_,name)\n",
    "        if not os.path.exists(dir_): os.makedirs(dir_)\n",
    "        save_path=os.path.join(dir_,name)+'.zip'\n",
    "        try:\n",
    "            download_url(session, quotes_url, save_path)\n",
    "            with zipfile.ZipFile(save_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(dir_)\n",
    "            zip_ref.close()\n",
    "            os.remove(save_path)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resolution= [1m, 5m, 1d, 1w]\n",
    "def mine_price_data(board,category,resolution,from_,to_):\n",
    "    df=get_board_category_listings(board,category)\n",
    "    lists_=df[['symbol','code','cat']].to_dict('records')\n",
    "    events=build_event_lists(lists_=lists_,resolution_=resolution,from_=from_,to_=to_)\n",
    "    crawl_data(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_quote_movements(board,category,from_,to_):\n",
    "    df=get_board_category_listings(board,category)\n",
    "    lists_=df[['symbol','code','cat']].to_dict('records')\n",
    "    events=build_event_lists(lists_=lists_,from_=from_,to_=to_)\n",
    "    for event in events:\n",
    "        events_=distribute_requests(event)\n",
    "        for event_ in events_:\n",
    "            crawl_quote_movements(event_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test case for mine_quote_movement\n",
    "generate_session()\n",
    "mine_quote_movements('Main Market','Industrial Products & Services',1591459200,1591977600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test case for mine price data\n",
    "mine_price_data('Main Market','Industrial Products & Services','1m',1591459200,1591977600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=lambda_handler(event)\n",
    "df=pd.read_json(res)\n",
    "#plot_timeseries(df)\n",
    "df['t']=pd.to_datetime(df['t'],unit='s')\n",
    "df=df.set_index('t').drop(['s'],axis=1)\n",
    "ta_indicators=ta.trend.IchimokuIndicator(high=df['h'],low=df['l'],visual=True,fillna=True)\n",
    "df['ichimoku_a']=ta_indicators.ichimoku_a()\n",
    "df['ichimoku_b']=ta_indicators.ichimoku_b()\n",
    "df['ichimoku_base_line']=ta_indicators.ichimoku_base_line()\n",
    "df['ichimoku_conversion_line']=ta_indicators.ichimoku_conversion_line()\n",
    "#df[['c','ichimoku_a','ichimoku_b','ichimoku_base_line','ichimoku_conversion_line']].iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['ichimoku_a'].values,\n",
    "    fill=None,\n",
    "    mode='lines',\n",
    "    line_color='blue',\n",
    "    ))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index,\n",
    "    y=df['ichimoku_b'].values,\n",
    "    fill='tonexty', # fill area between trace0 and trace1\n",
    "    mode='lines', line_color='green'))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index,\n",
    "    y=df['ichimoku_conversion_line'].values,\n",
    "    mode='lines', line_color='orange'))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index,\n",
    "    y=df['ichimoku_base_line'].values,\n",
    "    mode='lines', line_color='purple'))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index,\n",
    "    y=df['c'].values,\n",
    "    mode='lines', line_color='red'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=get_listings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
